{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adithya1610/EIP_3.0_Phase_2/blob/master/Session2/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90ANir8j2lcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import string\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUvM5Gt12yDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o84JpYfx20uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek9HjCFp3iC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "81efb75f-6b8a-4ff2-97c6-dcb9fcd74c4e"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  144524\n",
            "Total Vocab:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24vyLK13kst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "749ccf76-6644-4e18-fd68-1133a8551ab8"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  144424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFLq-Tpl3-Q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh-OyERQ4LPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHZTdYUR4PJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT1OQfWH4SbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9eb6c9a-e2ae-4f30-e367-52ecaa3c202e"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=4096, callbacks=callbacks_list)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "144424/144424 [==============================] - 17s 115us/step - loss: 3.2255\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.22547, saving model to weights-improvement-01-3.2255.hdf5\n",
            "Epoch 2/20\n",
            "144424/144424 [==============================] - 16s 111us/step - loss: 3.0639\n",
            "\n",
            "Epoch 00002: loss improved from 3.22547 to 3.06389, saving model to weights-improvement-02-3.0639.hdf5\n",
            "Epoch 3/20\n",
            "144424/144424 [==============================] - 16s 112us/step - loss: 3.0575\n",
            "\n",
            "Epoch 00003: loss improved from 3.06389 to 3.05746, saving model to weights-improvement-03-3.0575.hdf5\n",
            "Epoch 4/20\n",
            "144424/144424 [==============================] - 16s 113us/step - loss: 3.0526\n",
            "\n",
            "Epoch 00004: loss improved from 3.05746 to 3.05257, saving model to weights-improvement-04-3.0526.hdf5\n",
            "Epoch 5/20\n",
            "144424/144424 [==============================] - 16s 113us/step - loss: 3.0494\n",
            "\n",
            "Epoch 00005: loss improved from 3.05257 to 3.04942, saving model to weights-improvement-05-3.0494.hdf5\n",
            "Epoch 6/20\n",
            "144424/144424 [==============================] - 16s 114us/step - loss: 3.0458\n",
            "\n",
            "Epoch 00006: loss improved from 3.04942 to 3.04578, saving model to weights-improvement-06-3.0458.hdf5\n",
            "Epoch 7/20\n",
            "144424/144424 [==============================] - 17s 115us/step - loss: 3.0399\n",
            "\n",
            "Epoch 00007: loss improved from 3.04578 to 3.03990, saving model to weights-improvement-07-3.0399.hdf5\n",
            "Epoch 8/20\n",
            "144424/144424 [==============================] - 17s 116us/step - loss: 3.0296\n",
            "\n",
            "Epoch 00008: loss improved from 3.03990 to 3.02960, saving model to weights-improvement-08-3.0296.hdf5\n",
            "Epoch 9/20\n",
            "144424/144424 [==============================] - 17s 116us/step - loss: 3.0068\n",
            "\n",
            "Epoch 00009: loss improved from 3.02960 to 3.00681, saving model to weights-improvement-09-3.0068.hdf5\n",
            "Epoch 10/20\n",
            "144424/144424 [==============================] - 17s 117us/step - loss: 2.9669\n",
            "\n",
            "Epoch 00010: loss improved from 3.00681 to 2.96693, saving model to weights-improvement-10-2.9669.hdf5\n",
            "Epoch 11/20\n",
            "144424/144424 [==============================] - 17s 117us/step - loss: 2.9345\n",
            "\n",
            "Epoch 00011: loss improved from 2.96693 to 2.93447, saving model to weights-improvement-11-2.9345.hdf5\n",
            "Epoch 12/20\n",
            "144424/144424 [==============================] - 17s 117us/step - loss: 2.9151\n",
            "\n",
            "Epoch 00012: loss improved from 2.93447 to 2.91511, saving model to weights-improvement-12-2.9151.hdf5\n",
            "Epoch 13/20\n",
            "144424/144424 [==============================] - 17s 118us/step - loss: 2.9004\n",
            "\n",
            "Epoch 00013: loss improved from 2.91511 to 2.90035, saving model to weights-improvement-13-2.9004.hdf5\n",
            "Epoch 14/20\n",
            "144424/144424 [==============================] - 17s 118us/step - loss: 2.8837\n",
            "\n",
            "Epoch 00014: loss improved from 2.90035 to 2.88371, saving model to weights-improvement-14-2.8837.hdf5\n",
            "Epoch 15/20\n",
            "144424/144424 [==============================] - 17s 118us/step - loss: 2.8679\n",
            "\n",
            "Epoch 00015: loss improved from 2.88371 to 2.86791, saving model to weights-improvement-15-2.8679.hdf5\n",
            "Epoch 16/20\n",
            "144424/144424 [==============================] - 17s 119us/step - loss: 2.8519\n",
            "\n",
            "Epoch 00016: loss improved from 2.86791 to 2.85188, saving model to weights-improvement-16-2.8519.hdf5\n",
            "Epoch 17/20\n",
            "144424/144424 [==============================] - 17s 119us/step - loss: 2.8367\n",
            "\n",
            "Epoch 00017: loss improved from 2.85188 to 2.83665, saving model to weights-improvement-17-2.8367.hdf5\n",
            "Epoch 18/20\n",
            "144424/144424 [==============================] - 17s 119us/step - loss: 2.8196\n",
            "\n",
            "Epoch 00018: loss improved from 2.83665 to 2.81961, saving model to weights-improvement-18-2.8196.hdf5\n",
            "Epoch 19/20\n",
            "144424/144424 [==============================] - 17s 119us/step - loss: 2.8032\n",
            "\n",
            "Epoch 00019: loss improved from 2.81961 to 2.80320, saving model to weights-improvement-19-2.8032.hdf5\n",
            "Epoch 20/20\n",
            "144424/144424 [==============================] - 17s 119us/step - loss: 2.7896\n",
            "\n",
            "Epoch 00020: loss improved from 2.80320 to 2.78965, saving model to weights-improvement-20-2.7896.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f725c36d4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPmPoEPJ4eT7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrdUS3Tp4Vjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro8E5vot4fLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "2c74eaa2-adac-410c-f615-13f965ba4c9d"
      },
      "source": [
        "import sys\n",
        "\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" ose.\n",
            "\n",
            "the dormouse shook its head impatiently, and said, without opening its\n",
            "eyes, â€˜of course, of co \"\n",
            "e toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe to\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}